{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/f/ff/Uexternado.jpg\" width=\"240\" height=\"240\" align=\"right\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelos Supervisados\n",
    "\n",
    "## Random Forest y Voting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Andrés Martínez<br>\n",
    "Julio 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Métodos de Ensamble\n",
    "\n",
    "El objetivo de los métodos de ensamble es combinar diferentes clasificadores en un metaclasificador que tenga un mejor rendimiento de generalización que cada clasificador individual solo. Por ejemplo, suponiendo que recopilamos predicciones de 10 expertos, los métodos de ensamble nos permitirían combinar estratégicamente esas predicciones de los 10 expertos para llegar a una predicción que fuera más precisa y sólida que las predicciones de cada experto individual. Como verá más adelante en este capítulo, existen varios enfoques diferentes para crear un ensamble de clasificadores. Esta sección presentará una explicación básica de cómo funcionan los ensambles y por qué se les suele reconocer por producir un buen desempeño de generalización.\n",
    "\n",
    "Los métodos de ensamble más populares que utilizan el principio de votación por mayoría. La votación por mayoría simplemente significa que seleccionamos la etiqueta de clase que ha sido predicha por la mayoría de los clasificadores, es decir, recibió más del 50 por ciento de los votos. En sentido estricto, el término\n",
    "\"voto mayoritario\" se refiere únicamente a la configuración de clases binarias. Sin embargo, es fácil generalizar el principio de votación por mayoría a entornos multiclase, lo que se conoce como votación por pluralidad.\n",
    "\n",
    "![Picture title](image-20220726-143842.png)\n",
    "\n",
    "En la figura se observa como funcionan los métodos de ensamble, primero se generan lo métodos de clasificación, con nuevos datos, luego se obtienen las predicciones y finalmente se generan los votos para obtener el mejor clasificador.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La siguiente función usa un modelo binomial para determinar la probabilidad del error en los métodos de ensamble.\n",
    "\n",
    "\n",
    "$$ P(y\\geq k)= \\sum_{k}^{n} \\binom{n}{k} \\epsilon^{k} (1-\\epsilon)^{n-k}=\\epsilon_{ensamble}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "¿Cómo es posible que esta técnica funcione? La siguiente analogía puede ayudar a aclarar este misterio. Supongamos que tenemos una moneda ligeramente sesgada que tiene un 51% de posibilidades de salir cara y 49% de salir cruz. Si la lanza 1.000 veces, generalmente obtendrá más o menos 510 caras y 490 colas, y por tanto una mayoría de caras. Si hace los cálculos, descubrirá que la probabilidad de obtener una mayoría de caras después de 1.000 lanzamientos se acerca al 75%. Cuanto más lances la moneda, mayor será la probabilidad (por ejemplo, con 10.000 lanzamientos, la probabilidad supera el 97%). Esto se debe a la ley de los grandes números: a medida que se sigue lanzando la moneda, la proporción de caras se acerca cada vez más a la probabilidad de cara (51%). La figura siguiente muestra 10 series de lanzamientos de moneda sesgada. Puede ver que, a medida que aumenta el número de lanzamientos, la proporción de caras se acerca al 51%. Finalmente, las 10 series terminan tan cerca del 51% que se sitúan sistemáticamente por encima del 50%.\n",
    "\n",
    "Del mismo modo, suponga que construye un conjunto que contiene 1.000 clasificadores que, individualmente, sólo aciertan el 51% de las veces (apenas mejor que la adivinación aleatoria). Si predice la clase mayoritariamente votada, puede esperar una precisión de hasta el 75%. Sin embargo, esto sólo es cierto si todos los clasificadores son perfectamente independientes, cometiendo errores no correlacionados, lo cual no es que, evidentemente, no es el caso, ya que se han entrenado con los mismos datos. Es probable que cometan los mismos mismos tipos de errores, por lo que habrá muchos votos mayoritarios para la clase equivocada, reduciendo la precisión del conjunto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "heads_proba = 0.51\n",
    "coin_tosses = (np.random.rand(10000, 10) < heads_proba).astype(np.int32)\n",
    "cumulative_heads_ratio = np.cumsum(coin_tosses, axis=0) / np.arange(1, 10001).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función nos dice que si tomamos 11 clasificadores con una tasa de error promedio de 0.25, entonces la tasa de error del ensamble es 0.034, mucho menor que escoger un solo clasificador."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "error_range = np.arange(0.0, 1.01, 0.01)\n",
    "ens_errors = [ensemble_error(n_classifier=11, error=error)\n",
    "    for error in error_range]\n",
    "plt.plot(error_range,ens_errors,label='Ensemble error',linewidth=2)\n",
    "plt.plot(error_range, error_range,linestyle='--', label='Base error',linewidth=2)\n",
    "plt.xlabel('Base error')\n",
    "plt.ylabel('Base/Ensemble error')\n",
    "plt.legend(loc='upper left')\n",
    "plt.grid(alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.special import comb\n",
    "import math\n",
    "def ensemble_error(n_classifier, error):\n",
    "    k_start = int(math.ceil(n_classifier / 2.))\n",
    "    probs = [comb(n_classifier, k) * error**k * (1-error)**(n_classifier - k)\n",
    "        for k in range(k_start, n_classifier + 1)]\n",
    "    return sum(probs)\n",
    "\n",
    "ensemble_error(n_classifier=5, error=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(8,3.5))\n",
    "plt.plot(cumulative_heads_ratio)\n",
    "plt.plot([0, 10000], [0.51, 0.51], \"k--\", linewidth=2, label=\"51%\")\n",
    "plt.plot([0, 10000], [0.5, 0.5], \"k-\", label=\"50%\")\n",
    "plt.xlabel(\"Number of coin tosses\")\n",
    "plt.ylabel(\"Heads ratio\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.axis([0, 10000, 0.42, 0.58])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Voto por Mayoria\n",
    "\n",
    "El algoritmo que vamos a implementar en esta sección nos permitirá combinar diferentes algoritmos de clasificación asociados con pesos individuales por confianza. Nuestro objetivo es construir un metaclasificador más fuerte que equilibre las debilidades de los clasificadores individuales en un conjunto de datos en particular. En términos matemáticos más precisos, podemos escribir el voto de la mayoría ponderada de la siguiente manera:\n",
    "\n",
    "$$ \\hat{y}=arg max \\sum^{m}_{i=1}w_{j}X_{A}(C_{j}(x)=i)$$\n",
    "\n",
    "Donde $w_{j}$ es el peso del clasificador $C_{j}$. $\\hat{y}$ es la predicción del ensamble; A es el conjunto de etiquetas de clase únicas;$X_{A}$ es la función característica o función indicadora, que devuelve 1 si la clase predicha del clasificador j-ésimo coincide con $i (C_j(x) = i)$. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import ClassifierMixin\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import _name_estimators\n",
    "import numpy as np\n",
    "import operator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la siguiente función se genera el voto de los modelos que utilizarán de acuerdo a la predicción."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MajorityVoteClassifier(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, classifiers, vote='classlabel', weights=None):\n",
    "        self.classifiers = classifiers\n",
    "        self.named_classifiers = {\n",
    "            key: value for key,\n",
    "            value in _name_estimators(classifiers)\n",
    "        }\n",
    "        self.vote = vote\n",
    "        self.weights = weights\n",
    "    def fit(self, X, y):\n",
    "        if self.vote not in ('probability', 'classlabel'):\n",
    "            raise ValueError(f\"vote must be 'probability'\"f\"or 'classlabel'\"f\"; got (vote={self.vote})\")\n",
    "        if self.weights and len(self.weights) != len(self.classifiers):\n",
    "            raise ValueError(f'Number of classifiers and'f' weights must be equal'f'; got {len(self.weights)} weights,'f' {len(self.classifiers)} classifiers') # Use LabelEncoder to ensure class labels start\n",
    "# with 0, which is important for np.argmax # call in self.predict\n",
    "        self.lablenc_ = LabelEncoder() \n",
    "        self.lablenc_.fit(y)\n",
    "        self.classes_ = self.lablenc_.classes_\n",
    "        self.classifiers_ = []\n",
    "        for clf in self.classifiers:\n",
    "            fitted_clf = clone(clf).fit(X,\n",
    "                           self.lablenc_.transform(y))\n",
    "            self.classifiers_.append(fitted_clf)\n",
    "        return self\n",
    "    def predict(self, X):\n",
    "        if self.vote == 'probability':\n",
    "            maj_vote = np.argmax(self.predict_proba(X), axis=1) \n",
    "        else: # 'classlabel' vote\n",
    "            predictions = np.asarray([\n",
    "            clf.predict(X) for clf in self.classifiers_\n",
    "            ]).T\n",
    "            maj_vote = np.apply_along_axis(\n",
    "                lambda x: np.argmax(\n",
    "                    np.bincount(x, weights=self.weights)\n",
    "                ),\n",
    "                axis=1, arr=predictions\n",
    "            )\n",
    "        maj_vote = self.lablenc_.inverse_transform(maj_vote)\n",
    "        return maj_vote\n",
    "    def predict_proba(self, X):\n",
    "        probas = np.asarray([clf.predict_proba(X)\n",
    "                         for clf in self.classifiers_])\n",
    "        avg_proba = np.average(probas, axis=0,\n",
    "                           weights=self.weights)\n",
    "        return avg_proba\n",
    "    def get_params(self, deep=True):\n",
    "        if not deep:\n",
    "            return super().get_params(deep=False)\n",
    "        else:\n",
    "            out = self.named_classifiers.copy()\n",
    "            for name, step in self.named_classifiers.items():\n",
    "                for key, value in step.get_params(\n",
    "                    deep=True).items():\n",
    "                    out[f'{name}__{key}'] = value\n",
    "            return out\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con esta función se genera la predicción del método de ensamble combinando los diferentes clasificadores."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que ya estamos familiarizados con las técnicas para cargar conjuntos de datos desde archivos CSV, tomaremos un atajo y cargaremos el conjunto de datos de Iris desde el módulo de conjuntos de datos de scikit-learn. Además, solo seleccionaremos dos características, el ancho del sépalo y la longitud del pétalo, para que la tarea de clasificación sea más desafiante con fines ilustrativos. Aunque nuestro MajorityVoteClassifier generaliza a problemas multiclase, solo clasificaremos ejemplos de flores de las clases Iris-versicolor e Iris-virginica, con las que calcularemos el ROC AUC más adelante. El código es el siguiente:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[50:, [1, 2]], iris.target[50:]\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y)\n",
    "X_train, X_test, y_train, y_test =train_test_split(X, y,test_size=0.5,random_state=1,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este modelo usaremos la regresión logística, un árbol de desición y KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.linear_model import LogisticRegression \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.neighbors import KNeighborsClassifier \n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np\n",
    "clf1 = LogisticRegression(penalty='l2',C=0.001,solver='lbfgs',random_state=1) \n",
    "clf2 = DecisionTreeClassifier(max_depth=1,criterion='entropy',random_state=0) \n",
    "clf3 = KNeighborsClassifier(n_neighbors=1,p=2, metric='minkowski') \n",
    "pipe1 = Pipeline([['sc', StandardScaler()],['clf', clf1]])\n",
    "pipe3 = Pipeline([['sc', StandardScaler()],['clf', clf3]])\n",
    "clf_labels = ['Logistic regression', 'Decision tree', 'KNN'] \n",
    "print('10-fold cross validation:\\n')\n",
    "for clf, label in zip([pipe1, clf2, pipe3], clf_labels):\n",
    "    scores = cross_val_score(estimator=clf,X=X_train,y=y_train,cv=10, scoring='roc_auc')\n",
    "    print(f'ROC AUC: {scores.mean():.2f} 'f'(+/- {scores.std():.2f}) [{label}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quizás se pregunte por qué entrenamos la regresión logística y el clasificador de vecinos más cercanos como parte de una canalización. La razón detrás de esto es que, tanto la regresión logística como los algoritmos de k vecinos más cercanos (usando la métrica de distancia euclidiana) no son invariantes en escala, en contraste con los árboles de decisión. Aunque las características de Iris se miden todas en la misma escala (cm), es un buen hábito trabajar con características estandarizadas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mv_clf = MajorityVoteClassifier(classifiers=[pipe1, clf2, pipe3])\n",
    "clf_labels += ['Majority voting']\n",
    "all_clf = [pipe1, clf2, pipe3, mv_clf]\n",
    "for clf, label in zip(all_clf, clf_labels):\n",
    "    scores = cross_val_score(estimator=clf,X=X_train,y=y_train,cv=10,scoring=\"roc_auc\")\n",
    "    print(f'ROC AUC: {scores.mean():.2f} 'f'(+/- {scores.std():.2f}) [{label}]')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Eavluación del modelo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "colors = ['black', 'orange', 'blue', 'green']\n",
    "linestyles = [':', '--', '-.', '-']\n",
    "for clf, label, clr, ls in zip(all_clf, clf_labels, colors, linestyles): # assuming the label of the positive class is 1 y_pred = clf.fit(X_train,\n",
    "    y_pred =clf.fit(X_train, y_train).predict_proba(X_test)[:, 1] \n",
    "    fpr, tpr, thresholds = roc_curve(y_true=y_test,y_score=y_pred)\n",
    "    roc_auc = auc(x=fpr, y=tpr)\n",
    "    plt.plot(fpr,tpr,color=clr,linestyle=ls,label =f'{label} (auc = {roc_auc:.2f})')\n",
    "    \n",
    "plt.legend(loc='lower right')  \n",
    "plt.plot([0, 1], [0, 1], linestyle='--',color='gray',linewidth=2)\n",
    "plt.xlim([-0.1, 1.1])\n",
    "plt.ylim([-0.1, 1.1])\n",
    "plt.grid(alpha=0.5)\n",
    "plt.xlabel('False positive rate (FPR)') \n",
    "plt.ylabel('True positive rate (TPR)') \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train) \n",
    "from itertools import product\n",
    "x_min = X_train_std[:, 0].min() - 1\n",
    "x_max = X_train_std[:, 0].max() + 1\n",
    "y_min = X_train_std[:, 1].min() - 1\n",
    "y_max = X_train_std[:, 1].max() + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.1),np.arange(y_min, y_max, 0.1)) \n",
    "f, axarr = plt.subplots(nrows=2, ncols=2,sharex='col',sharey='row',figsize=(7, 5))\n",
    "for idx, clf, tt in zip(product([0, 1], [0, 1]), all_clf, clf_labels):\n",
    "    clf.fit(X_train_std, y_train)\n",
    "    Z = clf.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    axarr[idx[0], idx[1]].contourf(xx, yy, Z, alpha=0.3)\n",
    "    axarr[idx[0], idx[1]].scatter(X_train_std[y_train==0, 0],X_train_std[y_train==0, 1],c='blue',marker='^',s=50)\n",
    "    axarr[idx[0], idx[1]].scatter(X_train_std[y_train==1, 0],X_train_std[y_train==1, 1],c='green',marker='o',s=50)\n",
    "    axarr[idx[0], idx[1]].set_title(tt)\n",
    "plt.text(-3.5, -5.,s='Sepal width [standardized]',ha='center', va='center', fontsize=12) \n",
    "plt.text(-12.5, 4.5,s='Petal length [standardized]',ha='center', va='center',fontsize=12, rotation=90) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest\n",
    "\n",
    "En esta sección, vamos a analizar algunos de estos algoritmos, en especial, los de taxonomía lineal y no lineal. En cuanto a la taxonomía de conjunto o ensamblados, como los tipo boosting y bagging, los veremos posteriormente cuando ya tengamos una base sólida de estos primeros. Cada algoritmo será presentado desde dos perspectivas:\n",
    "* El paquete y la función utilizados para entrenar y hacer predicciones.\n",
    "* Las configuraciones en el paquete scikit-learn para cada algoritmo, estos es, la configuración de sus hiperparámetros.\n",
    "\n",
    "Si todos los clasificadores son capaces de estimar las probabilidades de clase (es decir, todos tienen un método predict_proba()), entonces puede decirle a Scikit-Learn que prediga la clase con la mayor probabilidad de clase, promediada entre todos los clasificadores individuales. Esto se llama votación suave. A menudo logra un mayor rendimiento que la votación dura porque da más peso a los votos de alta confianza. Lo único que hay que hacer es sustituir voting=\"hard\" por voting=\"soft\" y asegurarse de que todos los clasificadores pueden estimar las probabilidades de clase. Este no es el caso de la clase SVC por defecto, por lo que debe establecer su hiperparámetro de probabilidad en True (esto hará que la clase SVC utilice la validación cruzada para estimar las probabilidades de clase, ralentizando el entrenamiento, y añadirá un método predict_proba()). Si modifica el código anterior para utilizar la votación suave, verá que el clasificador de votación alcanza una precisión superior al 91,2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.tree import DecisionTreeClassifier \n",
    "from sklearn.tree import plot_tree \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import confusion_matrix \n",
    "from sklearn.metrics import plot_confusion_matrix \n",
    "from sklearn.metrics import plot_confusion_matrix \n",
    "from sklearn.metrics import roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bagging y Passing\n",
    "\n",
    "Una forma de obtener un conjunto diverso de clasificadores es utilizar algoritmos de entrenamiento muy diferentes, como acabamos de comentar. Otro enfoque es utilizar el mismo algoritmo de entrenamiento para cada predictor y entrenarlos en diferentes subconjuntos aleatorios del conjunto de entrenamiento. Cuando el muestreo se realiza con reemplazo, este método se denomina bagging (abreviatura de bootstrap aggregating ). Cuando el muestreo se realiza sin reemplazo, se denomina 'pasting'. En otras palabras, tanto el bagging como el pasting permiten muestrear las instancias de entrenamiento varias veces entre múltiples predictores, pero sólo el bagging permite muestrear las instancias de entrenamiento varias veces para el mismo predictor. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(), n_estimators=500,\n",
    "    max_samples=100, bootstrap=True, random_state=42)\n",
    "bag_clf.fit(X_train, y_train)\n",
    "y_pred = bag_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez entrenados todos los predictores, el conjunto puede hacer una predicción para una nueva instancia simplemente agregando las predicciones de todos los predictores. La función de agregación suele ser el modo estadístico (es decir, la predicción más frecuente, al igual que un clasificador de voto duro) para la clasificación, o la media para la regresión. Cada predictor individual tiene un sesgo mayor que si se entrenara con el conjunto de entrenamiento original, pero la agregación reduce tanto el sesgo como la varianza. En general, el resultado neto es que el conjunto tiene un sesgo similar pero una varianza menor que un único predictor entrenado en el conjunto de entrenamiento original."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "print(accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_clf = DecisionTreeClassifier(random_state=42)\n",
    "tree_clf.fit(X_train, y_train)\n",
    "y_pred_tree = tree_clf.predict(X_test)\n",
    "print(accuracy_score(y_test, y_pred_tree))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los predictores pueden ser entrenados en paralelo, a través de diferentes núcleos de CPU o incluso diferentes servidores. Del mismo modo, las predicciones pueden realizarse en paralelo. Esta es una de las razones por las que el bagging y el pasting son métodos tan populares.\n",
    "\n",
    "El parámetro n_jobs indica a Scikit-Learn el número de núcleos de CPU que debe utilizar para el entrenamiento y las predicciones (-1 indica a Scikit-Learn que debe utilizar todos los núcleos disponibles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "\n",
    "def plot_decision_boundary(clf, X, y, axes=[-1.5, 2.45, -1, 1.5], alpha=0.5, contour=True):\n",
    "    x1s = np.linspace(axes[0], axes[1], 100)\n",
    "    x2s = np.linspace(axes[2], axes[3], 100)\n",
    "    x1, x2 = np.meshgrid(x1s, x2s)\n",
    "    X_new = np.c_[x1.ravel(), x2.ravel()]\n",
    "    y_pred = clf.predict(X_new).reshape(x1.shape)\n",
    "    custom_cmap = ListedColormap(['#fafab0','#9898ff','#a0faa0'])\n",
    "    plt.contourf(x1, x2, y_pred, alpha=0.3, cmap=custom_cmap)\n",
    "    if contour:\n",
    "        custom_cmap2 = ListedColormap(['#7d7d58','#4c4c7f','#507d50'])\n",
    "        plt.contour(x1, x2, y_pred, cmap=custom_cmap2, alpha=0.8)\n",
    "    plt.plot(X[:, 0][y==0], X[:, 1][y==0], \"yo\", alpha=alpha)\n",
    "    plt.plot(X[:, 0][y==1], X[:, 1][y==1], \"bs\", alpha=alpha)\n",
    "    plt.axis(axes)\n",
    "    plt.xlabel(r\"$x_1$\", fontsize=18)\n",
    "    plt.ylabel(r\"$x_2$\", fontsize=18, rotation=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(ncols=2, figsize=(10,4), sharey=True)\n",
    "plt.sca(axes[0])\n",
    "plot_decision_boundary(tree_clf, X, y)\n",
    "plt.title(\"Decision Tree\", fontsize=14)\n",
    "plt.sca(axes[1])\n",
    "plot_decision_boundary(bag_clf, X, y)\n",
    "plt.title(\"Decision Trees with Bagging\", fontsize=14)\n",
    "plt.ylabel(\"\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest \n",
    "\n",
    "El algoritmo Random Forest introduce una aleatoriedad adicional en el crecimiento de los árboles; en lugar de buscar la mejor característica al dividir un nodo, busca la mejor característica entre un subconjunto aleatorio de características. El algoritmo da lugar a una mayor diversidad de árboles, lo que (de nuevo) supone un mayor sesgo a cambio de una menor varianza, lo que generalmente da lugar a un modelo globalmente mejor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rnd_clf = RandomForestClassifier(n_estimators=500, max_leaf_nodes=16, random_state=42)\n",
    "rnd_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rnd_clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random Forest es un conjunto de Árboles de Decisión, generalmente entrenado a través del método de bagging (o a veces de Pasting), normalmente con max_samples establecido al tamaño del conjunto de entrenamiento. En lugar de construir un BaggingClassifier y pasarle un DecisionTreeClassifier, se puede utilizar la clase RandomForestClassifier, que es más conveniente y está optimizada para los Árboles de Decisión (de forma similar, hay una clase RandomForestRegressor para tareas de regresión). \n",
    "\n",
    "El siguiente BaggingClassifier es aproximadamente equivalente al anterior RandomForestClassifier:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bag_clf = BaggingClassifier(\n",
    "    DecisionTreeClassifier(max_features=\"sqrt\", max_leaf_nodes=16),\n",
    "    n_estimators=500, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(y_pred == y_pred_rf) / len(y_pred)  # predicciones muy similares"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caso Clasificación. Credit Risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_credit = pd.read_csv('data_credit')\n",
    "df_credit=df_credit[['grade','emp_length_n', 'dti_n', 'revenue', 'loan_amnt', 'fico_n',\n",
    "       'purpose_car', 'purpose_credit_card', 'purpose_debt_consolidation',\n",
    "       'purpose_educational', 'purpose_home_improvement', 'purpose_house',\n",
    "       'purpose_major_purchase', 'purpose_medical', 'purpose_moving',\n",
    "       'purpose_other', 'purpose_renewable_energy',\n",
    "       'purpose_small_business', 'purpose_vacation', 'purpose_wedding',\n",
    "       'home_ownership_n_MORTGAGE', 'home_ownership_n_OTHER',\n",
    "       'home_ownership_n_OWN', 'home_ownership_n_RENT']]\n",
    "class_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "le = LabelEncoder()\n",
    "df_credit['grade'] = le.fit_transform(df_credit['grade'])\n",
    "df_credit['grade'].value_counts(normalize=True, sort=True, ascending=True)\n",
    "df_credit=df_credit.groupby('grade', group_keys=False).apply(lambda x: x.sample(frac=0.05, random_state=123))\n",
    "df_credit['grade'].value_counts(normalize=True, sort=True, ascending=True)\n",
    "df_credit['grade'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_credit.drop(labels=['grade', ], axis=1),df_credit['grade'], test_size=0.3, random_state=123, stratify=df_credit['grade'])\n",
    "\n",
    "#X_train_s = MinMaxScaler(X_train)\n",
    "scaler = MinMaxScaler()\n",
    "X_train_s=scaler.fit_transform(X_train)\n",
    "X_test_s=scaler.fit_transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "neurons=5\n",
    "optimizer='adam'\n",
    "\n",
    "def model_ann(neurons=neurons, optimizer=optimizer):\n",
    "  # creating the layers of the ANN\n",
    "  ann = tf.keras.models.Sequential()\n",
    "  ann.add(tf.keras.layers.Dense(units=neurons, input_dim=len(X_train.keys()), activation='relu'))\n",
    "  ann.add(tf.keras.layers.Dense(units=neurons, activation='relu'))\n",
    "  ann.add(tf.keras.layers.Dense(units=7, activation='softmax'))\n",
    "  # Compile model\n",
    "  ann.compile(optimizer=optimizer, loss = 'sparse_categorical_crossentropy', metrics = ['accuracy'])\n",
    "  return ann\n",
    "\n",
    "model=KerasClassifier(build_fn=model_ann, verbose=0)\n",
    "\n",
    "params={'batch_size':[50, 32], \n",
    "        'nb_epoch':[20, 50],\n",
    "        'neurons':[15, 30],\n",
    "       'optimizer':['rmsprop', 'adam'],}\n",
    "\n",
    "'''activations = ['tanh','relu','sigmoid']\n",
    "initializers = ['glorot_uniform', 'normal', 'uniform']'''\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=params, cv=3)\n",
    "grid_result = grid.fit(X_train_s, y_train, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimización de hiperparámetros. Estadísticas. Identificación del mejor conjunto de hiperparámetros"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"El mejor accuracy: {}\\nY la mejor combinación de hiperparámetros: {}\".format(grid_result.best_score_, \n",
    "                             grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "d_hhiper=pd.DataFrame(params)\n",
    "d_hhiper['Mean']=means\n",
    "d_hhiper['Std. Dev']=stds\n",
    "d_hhiper.sort_values(by='Mean', ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "param_ = ['batch_size','nb_epoch','neurons','optimizer']\n",
    "\n",
    "fig, ax = plt.subplots(2,2,figsize=(10,6), squeeze=False)\n",
    "ax = ax.ravel()\n",
    "for i in range(4):\n",
    "    ax[i].set_title('Distribution of mean accuracy with {}'.format(param_[i]))\n",
    "    sns.boxplot(x=param_[i],y='Mean',data=d_hhiper,ax=ax[i])\n",
    "fig.tight_layout(pad=1.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Diferentes algoritmos de modelación vs la \"mejor\" red. Desempeño - Stratified CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparar modelos\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import pandas\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "neurons=grid_result.best_params_['neurons']\n",
    "optimizer=grid_result.best_params_['optimizer']\n",
    "\n",
    "epochs=grid_result.best_params_['nb_epoch']\n",
    "batch_size=grid_result.best_params_['batch_size']\n",
    "\n",
    "model_ann_f = KerasClassifier(build_fn=model_ann, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "\n",
    "seed = 221\n",
    "models = []\n",
    "models.append(('MLR', LogisticRegression(random_state = 123)))\n",
    "models.append(('CART', DecisionTreeClassifier(random_state = 123)))\n",
    "models.append(('RF', RandomForestClassifier(random_state = 123)))\n",
    "models.append(('ANN', model_ann_f))\n",
    "# evaluate each model in turn\n",
    "results_c = []\n",
    "names_c = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    kfold = model_selection.StratifiedKFold(n_splits=5, shuffle=True, random_state=seed)\n",
    "    cv_results = model_selection.cross_val_score(model, X_train_s, y_train, cv=kfold, scoring=scoring)\n",
    "    results_c.append(cv_results)\n",
    "    names_c.append(name)\n",
    "    msg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n",
    "    print(msg)\n",
    "\n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "fig.suptitle('CV-ACC Comparación de algoritmos')\n",
    "ax = fig.add_subplot(111)\n",
    "plt.boxplot(results_c)\n",
    "ax.set_xticklabels(names_c)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Comparar modelos. Entrenamiento con DataTrain completo y evaluación con DataTest.\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import model_selection\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "import pandas\n",
    "import seaborn as sns\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "tf.random.set_seed(123)\n",
    "\n",
    "neurons=grid_result.best_params_['neurons']\n",
    "optimizer=grid_result.best_params_['optimizer']\n",
    "epochs=grid_result.best_params_['nb_epoch']\n",
    "batch_size=grid_result.best_params_['batch_size']\n",
    "\n",
    "model_ann_f = model_ann(neurons, optimizer)\n",
    "model_ann_f.fit(X_train_s, y_train, epochs=epochs, batch_size=batch_size, verbose=0)\n",
    "test_loss, test_acc = model_ann_f.evaluate(X_test_s, y_test, verbose=0)\n",
    "\n",
    "seed = 221\n",
    "models = []\n",
    "models.append(('MLR', LogisticRegression(random_state = 123)))\n",
    "models.append(('CART', DecisionTreeClassifier(random_state = 123)))\n",
    "models.append(('RF', RandomForestClassifier(random_state = 123)))\n",
    "# evaluate each model in turn\n",
    "results_t = []\n",
    "names_t = []\n",
    "scoring = 'accuracy'\n",
    "for name, model in models:\n",
    "    model.fit(X_train_s, y_train)\n",
    "    results_m=accuracy_score(y_test, model.predict(X_test_s))\n",
    "    results_t.append(results_m)\n",
    "    names_t.append(name)\n",
    "    msg = \"%s: %f\" % (name, results_m)\n",
    "    print(msg)\n",
    "print(\"%s: %f\" % ('ANN', test_acc))\n",
    "\n",
    "results_t.append(test_acc)\n",
    "names_t.append('ANN')\n",
    "\n",
    "\n",
    "# boxplot algorithm comparison\n",
    "fig = plt.figure()\n",
    "sns.set_style('darkgrid')\n",
    "fig.suptitle('Comparación de algoritmos en DataTest con ACC')\n",
    "ax = fig.add_subplot(111)\n",
    "sns.barplot(names_t, results_t)\n",
    "ax.bar_label(ax.containers[0], label_type='edge')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicción individual \n",
    "import numpy as np\n",
    "new_register = np.expand_dims(X_test_s[4,:],0)\n",
    "\n",
    "predictions_single = model_ann_f.predict(new_register)\n",
    "print(predictions_single)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['A', 'B', 'C', 'D', 'E', 'F', 'G']\n",
    "\n",
    "print('Predicción de Grade:', np.argmax(predictions_single[0]),\";\", 'Real Grade:', y_test.iloc[4])\n",
    "\n",
    "def plot_value_array(i, predictions, true_y):\n",
    "  predictions, true_y = predictions, true_y.iloc[i]\n",
    "  plt.grid(False)\n",
    "  plt.xticks(range(7))\n",
    "  plt.yticks([])\n",
    "  thisplot = plt.bar(range(7), predictions, color=\"#777777\")\n",
    "  plt.ylim([0, 1])\n",
    "  predicted_label = np.argmax(predictions)\n",
    "  thisplot[predicted_label].set_color('red')\n",
    "  thisplot[true_y].set_color('blue')\n",
    "\n",
    "plot_value_array(4, predictions_single[0], y_test)\n",
    "_ = plt.xticks(range(7), class_names, rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libreria Sklearn\n",
    "\n",
    "En esta sección, vamos a analizar algunos de estos algoritmos, en especial, los de taxonomía lineal y no lineal. En cuanto a la taxonomía de conjunto o ensamblados, como los tipo boosting y bagging, los veremos posteriormente cuando ya tengamos una base sólida de estos primeros. Cada algoritmo será presentado desde dos perspectivas:\n",
    "\n",
    "* El paquete y la función utilizados para entrenar y hacer predicciones.\n",
    "* Las configuraciones en el paquete scikit-learn para cada algoritmo, estos es, la configuración de sus hiperparámetros.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_moons\n",
    "\n",
    "X, y = make_moons(n_samples=500, noise=0.30, random_state=42)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=10, random_state=42)\n",
    "svm_clf = SVC(gamma=\"scale\", random_state=42)\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='hard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred =clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si todos los clasificadores son capaces de estimar las probabilidades de clase (es decir, todos tienen un método predict_proba()), entonces puede decirle a Scikit-Learn que prediga la clase con la mayor probabilidad de clase, promediada entre todos los clasificadores individuales. Esto se llama votación suave. A menudo logra un mayor rendimiento que la votación dura porque da más peso a los votos de alta confianza. Lo único que hay que hacer es sustituir voting=\"hard\" por voting=\"soft\" y asegurarse de que todos los clasificadores pueden estimar las probabilidades de clase. Este no es el caso de la clase SVC por defecto, por lo que debe establecer su hiperparámetro de probabilidad en True (esto hará que la clase SVC utilice la validación cruzada para estimar las probabilidades de clase, ralentizando el entrenamiento, y añadirá un método predict_proba()). Si modifica el código anterior para utilizar la votación suave, verá que el clasificador de votación alcanza una precisión superior al 91,2%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_clf = LogisticRegression(solver=\"lbfgs\", random_state=42)\n",
    "rnd_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "svm_clf = SVC(gamma=\"scale\", probability=True, random_state=42) # observe la modificación si necesitamos calcular las probabilidades asociadas\n",
    "\n",
    "voting_clf = VotingClassifier(\n",
    "    estimators=[('lr', log_clf), ('rf', rnd_clf), ('svc', svm_clf)],\n",
    "    voting='soft')\n",
    "voting_clf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for clf in (log_clf, rnd_clf, svm_clf, voting_clf):\n",
    "    clf.fit(X_train, y_train)\n",
    "    y_pred =clf.predict(X_test)\n",
    "    print(clf.__class__.__name__, accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
